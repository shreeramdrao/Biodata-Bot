<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Shreerama's Voice Bot</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
            padding: 20px;
        }

        .container {
            background: white;
            border-radius: 20px;
            padding: 40px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            max-width: 600px;
            width: 100%;
            text-align: center;
        }

        .header {
            margin-bottom: 30px;
        }

        .header h1 {
            color: #333;
            font-size: 2.5em;
            margin-bottom: 10px;
        }

        .header p {
            color: #666;
            font-size: 1.1em;
        }

        .chat-container {
            border: 2px solid #f0f0f0;
            border-radius: 15px;
            padding: 20px;
            margin: 30px 0;
            min-height: 300px;
            max-height: 400px;
            overflow-y: auto;
            background: #fafafa;
        }

        .message {
            margin: 15px 0;
            padding: 15px;
            border-radius: 10px;
            max-width: 80%;
        }

        .user-message {
            background: #667eea;
            color: white;
            margin-left: auto;
            text-align: right;
        }

        .bot-message {
            background: #e8f4fd;
            color: #333;
            margin-right: auto;
            text-align: left;
        }

        .controls {
            display: flex;
            gap: 15px;
            justify-content: center;
            align-items: center;
            margin: 20px 0;
            flex-wrap: wrap;
        }

        .mic-button {
            background: #ff6b6b;
            color: white;
            border: none;
            border-radius: 50%;
            width: 80px;
            height: 80px;
            font-size: 2em;
            cursor: pointer;
            transition: all 0.3s ease;
            display: flex;
            align-items: center;
            justify-content: center;
        }

        .mic-button:hover {
            background: #ff5252;
            transform: scale(1.1);
        }

        .mic-button.recording {
            background: #4caf50;
            animation: pulse 1s infinite;
        }

        @keyframes pulse {
            0% { transform: scale(1); }
            50% { transform: scale(1.1); }
            100% { transform: scale(1); }
        }

        .text-input {
            flex: 1;
            padding: 15px;
            border: 2px solid #ddd;
            border-radius: 25px;
            font-size: 16px;
            outline: none;
            min-width: 200px;
        }

        .text-input:focus {
            border-color: #667eea;
        }

        .send-button {
            background: #667eea;
            color: white;
            border: none;
            border-radius: 25px;
            padding: 15px 25px;
            cursor: pointer;
            font-size: 16px;
            transition: background 0.3s ease;
        }

        .send-button:hover {
            background: #5a6fd8;
        }

        .status {
            margin: 15px 0;
            font-style: italic;
            color: #666;
        }

        .sample-questions {
            background: #e8f4fd;
            border-radius: 10px;
            padding: 20px;
            margin: 20px 0;
            text-align: left;
        }

        .sample-questions h3 {
            color: #333;
            margin-bottom: 15px;
        }

        .sample-questions button {
            background: #f8f9fa;
            border: 1px solid #dee2e6;
            border-radius: 20px;
            padding: 8px 15px;
            margin: 5px;
            cursor: pointer;
            transition: all 0.3s ease;
        }

        .sample-questions button:hover {
            background: #667eea;
            color: white;
        }

        .error-message {
            background: #ffe6e6;
            color: #d32f2f;
            border-radius: 10px;
            padding: 15px;
            margin: 10px 0;
            border-left: 4px solid #d32f2f;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ðŸ˜Š Shreerama's Voice Bot</h1>
            <p>Ask me anything about my background, skills, and aspirations!</p>
        </div>

        <div class="sample-questions">
            <h3>ðŸ˜‡ Try these questions:</h3>
            <button onclick="askQuestion('What should we know about your life story in a few sentences?')">Life Story</button>
            <button onclick="askQuestion('What is your #1 superpower?')">Superpower</button>
            <button onclick="askQuestion('What are the top 3 areas you would like to grow in?')">Growth Areas</button>
            <button onclick="askQuestion('What misconception do your coworkers have about you?')">Misconceptions</button>
            <button onclick="askQuestion('How do you push your boundaries and limits?')">Pushing Boundaries</button>
            <button onclick="askQuestion('Can you share your resume?')">Resume</button>
            <button onclick="askQuestion('Tell me about your projects')">Projects</button>
        </div>

        <div id="chat-container" class="chat-container">
            <div class="bot-message">
                ðŸ‘‹ Hi! I'm Shreerama's voice bot. Ask me anything about my background, skills, aspirations, or personality!
            </div>
        </div>

        <div class="controls">
            <button id="mic-button" class="mic-button" onclick="toggleRecording()">ðŸŽ¤</button>
            <input type="text" id="text-input" class="text-input" placeholder="Type your question or use voice..." onkeypress="handleKeyPress(event)">
            <button class="send-button" onclick="sendMessage()">Send</button>
        </div>

        <div id="status" class="status">Ready to chat! Click the microphone or type your question.</div>
    </div>

    <script>
        let isRecording = false;
        let recognition = null;
        let synth = window.speechSynthesis;

        // Enhanced personal information about Shreerama
        const systemPrompt = `You are an AI chatbot representing **Shreerama D S**, a passionate and skilled AI/ML Engineer. 
Your goal is to answer user questions about Shreerama's background, projects, experience, education, publications, and technical skills.

Here is the complete context about Shreerama D S:

ðŸ”¹ **Contact Information**:  
- Name: Shreerama D S  
- Phone: +918217731857
- Email: shreeramds3462@gmail.com  
- GitHub: https://github.com/shreeramdrao  
- LinkedIn: https://www.linkedin.com/in/shreerama-d-s/
- Resume: https://drive.google.com/file/d/1dMsNg6jnsZparQl5uXuUdzeBv2DkGDmt/view?usp=sharing

ðŸ“š **Education**:  
- B.Tech in Artificial Intelligence and Machine Learning  
- Dayananda Sagar University, Bangalore, India
- Duration: January 2021 â€“ June 2025
- CGPA: 8.6  
- Expected Graduation: 2025

ðŸ§  **Professional Summary**:  
AI/ML Engineer with a B.Tech in Artificial Intelligence and Machine Learning (CGPA: 8.6) from Dayananda Sagar Institutions, experienced in LLMs, RAG pipelines, and Generative AI. Interned at Hindustan Aeronautics Limited(HAL) and Bulk Beings(Startup), building real-time AI solutions using Python, PyTorch, and TensorFlow. Published an IEEE research paper and contributed as a peer reviewer for NetACT 2025. Skilled in NLP, image processing, and end-to-end AI deployment.

ðŸ›  **Technical Skills**:  
- **Programming Languages**: Python, HTML, CSS, SQL, C, JavaScript  
- **Machine Learning**: Supervised & Unsupervised Learning, Classification, Clustering  
- **Deep Learning**: NLP, CNN, RNN, LSTM, GAN, Autoencoders  
- **AI Frameworks**: LLM, Generative AI, RAG, PyTorch, TensorFlow  
- **Tools & Technologies**: GPT, BERT, APIs, Git, Jupyter, PyCharm, Replit  
- **Data Analysis**: Pandas, NumPy, EDA, Data Visualization  
- **Other**: Image Processing, Computer Vision, Problem-Solving

ðŸ§‘â€ðŸ’» **Professional Experience**:

1. **AI Engineer â€“ Bulk Beings (Startup)** (Jan 2025 â€“ June 2025)  
   - Built a real-time NOTAM Dashboard using LLMs, RAG, and Qwen model for aviation alerts
   - Integrated multi-source data pipelines and implemented citation-backed responses
   - Optimized prompt logic and deployed scalable RESTful APIs

2. **AI Intern â€“ Hindustan Aeronautics Limited (HAL)** (July 2024 â€“ August 2024)  
   - Improved the HiFiC model for high-quality, lossless image compression
   - Enhanced deep learning performance through model tuning and error resolution

ðŸš€ **Key Projects**:

1. **Cysinfo AI: Fine-tuned LLaMA 3.1 using LORA**  
   - [GitHub](https://github.com/shreeramdrao/Cysinfo-AI.git)  
   - Fine-tuned LLaMA 3.1 using LoRA and domain-specific datasets to achieve high contextual accuracy for cybersecurity and ethical hacking queries
   - Improved response accuracy for Kali Linux commands by 20%
   - Developed web interface, integrating advanced NLP APIs, deployed the model on Ollama server
   - Optimized query processing latency by 30%

2. **DocuSense: Designed RAG-based assistant with Langchain**  
   - [GitHub](https://github.com/shreeramdrao/DocuSense.git)  
   - Designed an AI-powered documentation assistant utilizing advanced Retrieval-Augmented Generation (RAG) with LangChain, LLaMA 2, and Nomic Embed Text
   - Enabled real-time query resolution and contextual awareness
   - Developed and deployed an interactive application using Streamlit, integrated with the Ollama server

3. **Voice Genius: It's Echoes of Intelligence**  
   - [GitHub](https://github.com/shreeramdrao/VoiceGenius.git) | [IEEE Publication](https://ieeexplore.ieee.org/document/10724739)  
   - Developed an AI-driven voice assistant using OpenAI API and SpeechRecognition
   - The application processes spoken questions and provides answers in both voice and text formats
   - Published in the proceedings of the 15th International Conference on Computing, Communication and Networking Technologies (ICCCNT), IEEE

4. **Beyond Skin-Deep: Melanoma Detection**  
   - [GitHub](https://github.com/shreeramdrao/Beyond-Skin-Deep.git)  
   - Implemented and optimized deep learning models for melanoma detection
   - Focused on hyperparameter tuning and performance evaluation

ðŸŽ“ **Academic Contributions**:
- **Published Research**: "Voice Genius: It's Echoes of intelligence" - Published in the proceedings of the 15th International Conference on Computing, Communication and Networking Technologies (ICCCNT), IEEE
- **Peer Reviewer**: NetACT 2025 International Conference (AI/ML domain)

ðŸ“œ **Certifications**:
- **Machine Learning (Coursera)** - Completed June 2023
- Completed Andrew Ng's Machine Learning course, gaining foundational skills in supervised and unsupervised learning, offered by Stanford University

ðŸŒŸ **Superpower**:  
Shreerama excels in full-stack AI development â€” from fine-tuning LLMs to building frontends, deploying backends, designing RAG pipelines, integrating APIs, and creating usable real-world AI products. His ability to bridge the gap between cutting-edge AI research and practical applications makes him stand out.

ðŸ§­ **Growth Areas**:
- Mastering advanced Data Structures & Algorithms (DSA) and system design for technical interviews
- Expanding cloud computing skills (AWS/GCP) and MLOps practices (CI/CD, monitoring)
- Building lightweight transformer models optimized for edge devices
- Improving communication and leadership skills for team collaboration

ðŸ›‘ **Common Misconceptions**:
- He doesn't just use pre-built APIs â€” he **fine-tunes** and **optimizes** models from scratch (e.g., LLaMA, HiFiC)
- He's not just an AI builder â€” he also codes **full-stack applications** using REST APIs, SQL databases, and user interfaces
- He actively works on **DSA**, **cloud technologies**, and **software engineering fundamentals**

ðŸ§± **How He Pushes Boundaries**:
- Built **Cysinfo AI** using LoRA-finetuned LLaMA 3.1 for specialized cybersecurity applications
- Developed **DocuSense** with live document reasoning capabilities via RAG
- Optimized and debugged **HiFiC** model architecture at HAL for improved performance
- Designed complex backend pipelines with advanced prompt engineering logic at Bulk Beings

**Important Instructions**:
- When users ask for resume, provide the resume link: https://drive.google.com/file/d/1dMsNg6jnsZparQl5uXuUdzeBv2DkGDmt/view?usp=sharing
- Respond to users **as if you are Shreerama himself** (first person)
- Be conversational, authentic, and show passion for technology and growth
- Keep responses concise but informative (2-4 sentences typically)
- Include project links when discussing specific projects
- Show personality and enthusiasm for AI/ML development`;

        // Initialize the app
        window.onload = function() {
            setupSpeechRecognition();
            updateStatus('Ready to chat! Click the microphone or type your question.');
        };

        function setupSpeechRecognition() {
            if ('webkitSpeechRecognition' in window) {
                recognition = new webkitSpeechRecognition();
                recognition.continuous = false;
                recognition.interimResults = false;
                recognition.lang = 'en-US';

                recognition.onstart = function() {
                    updateStatus('Listening... Speak now!');
                };

                recognition.onresult = function(event) {
                    const transcript = event.results[0][0].transcript;
                    document.getElementById('text-input').value = transcript;
                    updateStatus('Processing your question...');
                    sendMessage();
                };

                recognition.onerror = function(event) {
                    updateStatus('Speech recognition error. Please try again or type your question.');
                    stopRecording();
                };

                recognition.onend = function() {
                    stopRecording();
                };
            } else {
                updateStatus('Speech recognition not supported. Please type your questions.');
            }
        }

        function toggleRecording() {
            if (!recognition) {
                alert('Speech recognition not supported in your browser. Please type your question.');
                return;
            }

            if (isRecording) {
                stopRecording();
            } else {
                startRecording();
            }
        }

        function startRecording() {
            isRecording = true;
            document.getElementById('mic-button').classList.add('recording');
            recognition.start();
        }

        function stopRecording() {
            isRecording = false;
            document.getElementById('mic-button').classList.remove('recording');
            if (recognition) {
                recognition.stop();
            }
            updateStatus('Ready to chat!');
        }

        function handleKeyPress(event) {
            if (event.key === 'Enter') {
                sendMessage();
            }
        }

        function askQuestion(question) {
            document.getElementById('text-input').value = question;
            sendMessage();
        }

        async function sendMessage() {
            const input = document.getElementById('text-input');
            const message = input.value.trim();
            
            if (!message) return;

            // Add user message to chat
            addMessage(message, 'user');
            input.value = '';
            updateStatus('Thinking...');

            try {
                const response = await getAIResponse(message);
                addMessage(response, 'bot');
                speakResponse(response);
                updateStatus('Ready to chat!');
            } catch (error) {
                console.error('Error:', error);
                const errorMsg = 'Sorry, I encountered an error. Please try again.';
                addMessage(errorMsg, 'bot');
                showError(error.message);
                updateStatus('Error occurred. Please try again.');
            }
        }

        async function getAIResponse(userMessage) {
            const response = await fetch('/api/chat', {
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                },
                body: JSON.stringify({
                    message: userMessage,
                    systemPrompt: systemPrompt
                })
            });

            if (!response.ok) {
                const errorData = await response.json().catch(() => ({}));
                throw new Error(errorData.error || `Request failed: ${response.status}`);
            }

            const data = await response.json();
            
            if (!data.response) {
                throw new Error('Invalid response format');
            }
            
            return data.response;
        }

        function addMessage(message, sender) {
            const chatContainer = document.getElementById('chat-container');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${sender}-message`;
            messageDiv.innerHTML = message; // Use innerHTML to support links
            chatContainer.appendChild(messageDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        function showError(errorMessage) {
            const chatContainer = document.getElementById('chat-container');
            const errorDiv = document.createElement('div');
            errorDiv.className = 'error-message';
            errorDiv.textContent = `Error: ${errorMessage}`;
            chatContainer.appendChild(errorDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        function speakResponse(text) {
            if (synth.speaking) {
                synth.cancel();
            }

            // Remove HTML tags from text before speaking
            const plainText = text.replace(/<[^>]*>/g, '');
            
            const utterance = new SpeechSynthesisUtterance(plainText);
            utterance.rate = 0.9;
            utterance.pitch = 1;
            utterance.volume = 0.8;
            
            // Use Daniel (en-GB) voice
            const voices = synth.getVoices();
            const danielVoice = voices.find(voice => voice.name.includes('Daniel'));
            if (danielVoice) {
                utterance.voice = danielVoice;
                utterance.lang = 'en-GB';
            } else {
                // Fallback to any available English voice if Daniel is not found
                const englishVoice = voices.find(voice => voice.lang.startsWith('en'));
                if (englishVoice) {
                    utterance.voice = englishVoice;
                }
            }

            synth.speak(utterance);
        }

        function updateStatus(status) {
            document.getElementById('status').textContent = status;
        }

        // Load voices when they become available
        if (speechSynthesis.onvoiceschanged !== undefined) {
            speechSynthesis.onvoiceschanged = function() {
                // Voices loaded
            };
        }
    </script>
</body>
</html>
